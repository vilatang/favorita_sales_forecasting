{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jenna\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "import math\n",
    "\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG = True\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    df_train = pd.read_csv(\n",
    "        'train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "        dtype={'onpromotion': bool},\n",
    "        converters={'unit_sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0},\n",
    "        parse_dates=[\"date\"],\n",
    "        skiprows=range(1, 111007527)  # Only Include 2017-01-01\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    df_train = pd.read_csv('df_20170401.csv',\n",
    "                           usecols=[0, 1, 2, 3, 4],\n",
    "                           dtype={'onpromotion': bool},\n",
    "                           parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "                      dtype={'onpromotion': bool},\n",
    "                      parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Item Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96995</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99197</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103501</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_nbr     family  class  perishable\n",
       "0     96995  GROCERY I   1093           0\n",
       "1     99197  GROCERY I   1067           0\n",
       "2    103501   CLEANING   3008           0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv(\"items.csv\")\n",
    "items.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Number of Stores in `Train` and `Test` Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Stores in Train Data Set: 54\n",
      "Num of Stores in Test Data Set: 54\n"
     ]
    }
   ],
   "source": [
    "num_store_train = df_train['store_nbr'].drop_duplicates().shape[0]\n",
    "num_store_test = df_test['store_nbr'].drop_duplicates().shape[0]\n",
    "\n",
    "print(\"Num of Stores in Train Data Set: {}\".format(num_store_train))\n",
    "print(\"Num of Stores in Test Data Set: {}\".format(num_store_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Number of Items in `Train`, `Test` and `Item` Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Items in Train Data Set: 3989\n",
      "Num of Items in Test Data Set: 3901\n",
      "Num of Items in Item Data Set: 4100\n"
     ]
    }
   ],
   "source": [
    "num_item_train = df_train['item_nbr'].drop_duplicates().shape[0]\n",
    "num_item_test = df_test['item_nbr'].drop_duplicates().shape[0]\n",
    "num_item = items['item_nbr'].drop_duplicates().shape[0]\n",
    "\n",
    "print(\"Num of Items in Train Data Set: {}\".format(num_item_train))\n",
    "print(\"Num of Items in Test Data Set: {}\".format(num_item_test))\n",
    "print(\"Num of Items in Item Data Set: {}\".format(num_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Many Common Items in Both Training and Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Common Items: 3841\n"
     ]
    }
   ],
   "source": [
    "num_common_items = len(set(df_train['item_nbr'].drop_duplicates()) & set(df_test['item_nbr'].drop_duplicates()))\n",
    "print(\"Num of Common Items: {}\".format(num_common_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Many Item Categories in `Item` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Items Category in Item Data Set: 33\n"
     ]
    }
   ],
   "source": [
    "num_item_category = items['family'].drop_duplicates().shape[0]\n",
    "print(\"Num of Items Category in Item Data Set: {}\".format(num_item_category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Perishable Item Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DELI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>POULTRY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EGGS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>DAIRY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>MEATS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              family  perishable\n",
       "4       BREAD/BAKERY           1\n",
       "15              DELI           1\n",
       "20           POULTRY           1\n",
       "21              EGGS           1\n",
       "54             DAIRY           1\n",
       "132            MEATS           1\n",
       "198          SEAFOOD           1\n",
       "237   PREPARED FOODS           1\n",
       "1709         PRODUCE           1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_category = items[['family', 'perishable']].drop_duplicates()\n",
    "item_category[item_category['perishable']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Perishable Item Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_category_percentage = item_category.groupby('perishable').count()\n",
    "item_category_percentage = item_category_percentage.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perishable</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   perishable  family\n",
       "0           0      24\n",
       "1           1       9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_category_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {\n",
    "    1: 'perishable', \n",
    "    0: 'non-perishable'\n",
    "}\n",
    "\n",
    "item_category_percentage = item_category_percentage.applymap(lambda s: mapper.get(s) if s in mapper else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perishable</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-perishable</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perishable</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       perishable  family\n",
       "0  non-perishable      24\n",
       "1      perishable       9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_category_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(8, 8))\n",
    "plt.title(\"Perishable Item Category vs Non-perishable Item Category\")\n",
    "axs.pie(item_category_percentage['family'], labels=item_category_percentage['perishable'], autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Percentage of Promotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Promotions: 12.1%\n"
     ]
    }
   ],
   "source": [
    "percentage_promo = df_train[df_train['onpromotion']==True].shape[0] / df_train.shape[0]\n",
    "print(\"Percentage of Promotions: {:.1%}\".format(percentage_promo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot the dataset so that it has dates as the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_data (df, values, ind, col, fill_value):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    value : the columns to be aggregated\n",
    "    ind : index\n",
    "    col : the existing in to be set as column\n",
    "    \n",
    "    Returns: Pivot table of df\n",
    "    '''\n",
    "    df = df.set_index(ind + col)[values].unstack(level = -1).fillna(fill_value)\n",
    "    \n",
    "    # Unstack will create multi-layer hiarachical columns, only use the level 1 column which is col\n",
    "    df.columns = df.columns.get_level_values(1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>103520</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>103665</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "0 2017-04-01          1    103520    0.693147        False\n",
       "1 2017-04-01          1    103665    0.693147        False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_promo = pivot_data (df_train, ['onpromotion'], ['store_nbr','item_nbr'], ['date'], False )\n",
    "df_test_promo = pivot_data (df_test, ['onpromotion'], ['store_nbr','item_nbr'], ['date'], False )\n",
    "df_train_sales = pivot_data (df_train, ['unit_sales'], ['store_nbr','item_nbr'], ['date'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-04-01 00:00:00</th>\n",
       "      <th>2017-04-02 00:00:00</th>\n",
       "      <th>2017-04-03 00:00:00</th>\n",
       "      <th>2017-04-04 00:00:00</th>\n",
       "      <th>2017-04-05 00:00:00</th>\n",
       "      <th>2017-04-06 00:00:00</th>\n",
       "      <th>2017-04-07 00:00:00</th>\n",
       "      <th>2017-04-08 00:00:00</th>\n",
       "      <th>2017-04-09 00:00:00</th>\n",
       "      <th>2017-04-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06 00:00:00</th>\n",
       "      <th>2017-08-07 00:00:00</th>\n",
       "      <th>2017-08-08 00:00:00</th>\n",
       "      <th>2017-08-09 00:00:00</th>\n",
       "      <th>2017-08-10 00:00:00</th>\n",
       "      <th>2017-08-11 00:00:00</th>\n",
       "      <th>2017-08-12 00:00:00</th>\n",
       "      <th>2017-08-13 00:00:00</th>\n",
       "      <th>2017-08-14 00:00:00</th>\n",
       "      <th>2017-08-15 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-04-01  2017-04-02  2017-04-03  2017-04-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995            0.0         0.0         0.0         0.0   \n",
       "          99197            0.0         0.0         0.0         0.0   \n",
       "\n",
       "date                2017-04-05  2017-04-06  2017-04-07  2017-04-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995            0.0         0.0    1.098612         0.0   \n",
       "          99197            0.0         0.0    0.000000         0.0   \n",
       "\n",
       "date                2017-04-09  2017-04-10     ...      2017-08-06  \\\n",
       "store_nbr item_nbr                             ...                   \n",
       "1         96995            0.0         0.0     ...        1.098612   \n",
       "          99197            0.0         0.0     ...        0.000000   \n",
       "\n",
       "date                2017-08-07  2017-08-08  2017-08-09  2017-08-10  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       1.098612         0.0    0.000000    0.693147   \n",
       "          99197       1.098612         0.0    1.098612    0.000000   \n",
       "\n",
       "date                2017-08-11  2017-08-12  2017-08-13  2017-08-14  2017-08-15  \n",
       "store_nbr item_nbr                                                              \n",
       "1         96995            0.0         0.0         0.0         0.0         0.0  \n",
       "          99197            0.0         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[2 rows x 137 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_sales.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min-max normalization of the unit_sales data in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_min = df_train_sales.sub(df_train_sales.min(axis=1), axis=0)\n",
    "#max_min = df_train_sales.max(axis=1) - df_train_sales.min(axis=1)\n",
    "#df_train_sales = sub_min.divide(max_min,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unifying the index of test and train promo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_promo = df_test_promo.reindex(df_train_promo.index, fill_value = False)\n",
    "items = items.set_index(\"item_nbr\").reindex(df_train_sales.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Promo Train and Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_promo = pd.concat([df_train_promo, df_test_promo], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-04-01 00:00:00</th>\n",
       "      <th>2017-04-02 00:00:00</th>\n",
       "      <th>2017-04-03 00:00:00</th>\n",
       "      <th>2017-04-04 00:00:00</th>\n",
       "      <th>2017-04-05 00:00:00</th>\n",
       "      <th>2017-04-06 00:00:00</th>\n",
       "      <th>2017-04-07 00:00:00</th>\n",
       "      <th>2017-04-08 00:00:00</th>\n",
       "      <th>2017-04-09 00:00:00</th>\n",
       "      <th>2017-04-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-22 00:00:00</th>\n",
       "      <th>2017-08-23 00:00:00</th>\n",
       "      <th>2017-08-24 00:00:00</th>\n",
       "      <th>2017-08-25 00:00:00</th>\n",
       "      <th>2017-08-26 00:00:00</th>\n",
       "      <th>2017-08-27 00:00:00</th>\n",
       "      <th>2017-08-28 00:00:00</th>\n",
       "      <th>2017-08-29 00:00:00</th>\n",
       "      <th>2017-08-30 00:00:00</th>\n",
       "      <th>2017-08-31 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-04-01  2017-04-02  2017-04-03  2017-04-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "\n",
       "date                2017-04-05  2017-04-06  2017-04-07  2017-04-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "\n",
       "date                2017-04-09  2017-04-10     ...      2017-08-22  \\\n",
       "store_nbr item_nbr                             ...                   \n",
       "1         96995          False       False     ...           False   \n",
       "          99197          False       False     ...           False   \n",
       "\n",
       "date                2017-08-23  2017-08-24  2017-08-25  2017-08-26  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "\n",
       "date                2017-08-27  2017-08-28  2017-08-29  2017-08-30  2017-08-31  \n",
       "store_nbr item_nbr                                                              \n",
       "1         96995          False       False       False       False       False  \n",
       "          99197          False       False       False       False       False  \n",
       "\n",
       "[2 rows x 153 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_promo.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate past n days' date index range\n",
    "def past_date_range_index(day, n_days):\n",
    "    date_index = pd.date_range(day - timedelta(days=n_days), \n",
    "                               day, \n",
    "                               closed='left')\n",
    "    return date_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate past nth day's date index\n",
    "def past_date_index (day,n_days):\n",
    "    date_index = day - timedelta(days = n_days)\n",
    "    return date_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate feature, target and promo set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation(df_sales, df_promo, pred_date, target_on):\n",
    "\n",
    "    # Generate the date range starting from the pred_date\n",
    "    future_date_range = pd.date_range(pred_date, periods=16)\n",
    "\n",
    "    # Create empty feature set\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    period=[3, 4, 5, 6, 7, 14, 21]\n",
    "    for n_days in period:\n",
    "        \n",
    "        # Feature Type 1: Past n Days' Sales Mean\n",
    "        date_index = past_date_range_index(pred_date, n_days)\n",
    "        features['past_{}day_mean'.format(n_days)] =  df_sales[date_index].mean(axis=1)\n",
    " \n",
    "        # Feature Type 2: Past n Days' Sales Decaying Sum (Exponential). \n",
    "        # Decaying factor = 0.9 \n",
    "        df_tmp1 = df_sales[date_index]\n",
    "        features['past_{}day_sum_decay'.format(n_days)] = \\\n",
    "          (df_tmp1 * np.power(0.9, np.arange(n_days)[::-1])).sum(axis=1)\n",
    "    \n",
    "\n",
    "    # Feature Type 3: Past nth Day Sales\n",
    "    period = [1, 2, 3, 4, 5, 6, 7]\n",
    "    for n_day in period:\n",
    "        date_index = past_date_index(pred_date, n_day)\n",
    "        features['past_{}th_day'.format(n_day)] =  df_sales[date_index]   \n",
    "\n",
    "        \n",
    "    # Feature Type 4: Past n days' Total Number of Promotion of Each Item\n",
    "    period=[3, 4, 5, 6, 7, 14, 21]\n",
    "    for n_days in period:\n",
    "        date_index = past_date_range_index(pred_date, n_days)\n",
    "        features['Past_{}day_tot_promo'.format(n_days)] =  df_promo[date_index].sum(axis=1) \n",
    "\n",
    "    # Feature Type 5: Future Promotion      \n",
    "    mapper = {\n",
    "        True: 1, \n",
    "        False: 0\n",
    "    }\n",
    "    future_promo = df_promo[future_date_range].applymap(lambda s: mapper.get(s) if s in mapper else False)\n",
    "\n",
    "    # For generating test data, no target is returned.\n",
    "    if target_on:\n",
    "        target = df_sales[future_date_range]\n",
    "        \n",
    "        return features,target, future_promo\n",
    "   \n",
    "    return features, future_promo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation, Test Date preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select one `Boundary Day` for each `training`, `validation` and `test` data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date = datetime.datetime(2017, 7, 5)\n",
    "val_date = datetime.datetime (2017, 7, 12)\n",
    "test_date = datetime.datetime (2017, 8, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate `Training` data set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train, target_train, future_promo_train = \\\n",
    "   feature_generation(df_train_sales,\n",
    "                      df_promo,\n",
    "                      train_date,\n",
    "                      True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate `Validation` data set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_val, target_val, future_promo_val = \\\n",
    "   feature_generation(df_train_sales,\n",
    "                      df_promo,\n",
    "                      val_date,\n",
    "                      True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate `Test` data set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test, future_promo_test = \\\n",
    "   feature_generation(df_train_sales,\n",
    "                      df_promo,\n",
    "                      test_date,\n",
    "                      False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate weight matrix for perishable items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = np.array(items['perishable']) * 0.25 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "Training one model per prediciton date, total 16 models will be trained for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred_days = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1. Random Forest Regression (RFR)\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training Random Forest Regression Model #0 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #1 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #2 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #3 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #4 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #5 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #6 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #7 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #8 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #9 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #10 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #11 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #12 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #13 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #14 ...\n",
      "\n",
      "==================================================\n",
      "Training Random Forest Regression Model #15 ...\n",
      "\n",
      "Time of Training 16 Random Forest Regression Models: 8.06 Mins\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "if DEBUG:\n",
    "    n_estimators_ = 1\n",
    "else:\n",
    "    n_estimators_ = 10\n",
    "    \n",
    "model_RF_all = [] # Model list for storing all 16 models\n",
    "feature_train_add = pd.DataFrame()\n",
    "feature_val_add = pd.DataFrame()\n",
    "feature_test_add = pd.DataFrame()\n",
    "\n",
    "# future_promo contains 16 days data, get the one on prediction date and use as a feature\n",
    "\n",
    "for i in range(n_pred_days): \n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print('Training Random Forest Regression Model #{} ...'.format(i))\n",
    "\n",
    "    feature_train_add = pd.concat([feature_train,future_promo_train.iloc[:,i]], axis=1)\n",
    "    feature_val_add = pd.concat([feature_val,future_promo_val.iloc[:,i]], axis=1)\n",
    "    feature_test_add = pd.concat([feature_test,future_promo_test.iloc[:,i]], axis=1)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators = n_estimators_, random_state = 50)\n",
    "    model = model.fit(feature_train_add, target_train.iloc[:,i])\n",
    "\n",
    "    model_RF_all.append(model)\n",
    "\n",
    "    print(\"\")\n",
    "    \n",
    "end = time.time()\n",
    "print (\"Time of Training {} Random Forest Regression Models: {:.2f} Mins\".format(n_pred_days, (end - start) / 60))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #0]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.630298\n",
      "1   past_14day_sum_decay  0.076320\n",
      "2        past_21day_mean  0.025816\n",
      "3        past_14day_mean  0.022246\n",
      "4         past_7day_mean  0.021614\n",
      "5      predict_day_promo  0.020341\n",
      "6    past_7day_sum_decay  0.016750\n",
      "7    past_6day_sum_decay  0.012885\n",
      "8           past_1th_day  0.012540\n",
      "9    past_3day_sum_decay  0.012440\n",
      "10   past_5day_sum_decay  0.012347\n",
      "11          past_3th_day  0.012111\n",
      "12   past_4day_sum_decay  0.012067\n",
      "13          past_7th_day  0.011893\n",
      "14          past_2th_day  0.011306\n",
      "15          past_4th_day  0.011294\n",
      "16        past_6day_mean  0.010915\n",
      "17        past_5day_mean  0.010333\n",
      "18        past_4day_mean  0.009667\n",
      "19          past_5th_day  0.009584\n",
      "20          past_6th_day  0.008888\n",
      "21        past_3day_mean  0.008281\n",
      "22  Past_21day_tot_promo  0.004618\n",
      "23   Past_6day_tot_promo  0.004272\n",
      "24   Past_7day_tot_promo  0.003902\n",
      "25  Past_14day_tot_promo  0.003795\n",
      "26   Past_5day_tot_promo  0.001581\n",
      "27   Past_3day_tot_promo  0.000981\n",
      "28   Past_4day_tot_promo  0.000914\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #1]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.493791\n",
      "1   past_14day_sum_decay  0.176322\n",
      "2        past_21day_mean  0.029693\n",
      "3        past_14day_mean  0.024011\n",
      "4    past_7day_sum_decay  0.023631\n",
      "5         past_7day_mean  0.019531\n",
      "6    past_6day_sum_decay  0.016253\n",
      "7         past_6day_mean  0.015811\n",
      "8      predict_day_promo  0.015791\n",
      "9           past_3th_day  0.014631\n",
      "10   past_5day_sum_decay  0.014619\n",
      "11   past_4day_sum_decay  0.014065\n",
      "12   past_3day_sum_decay  0.014023\n",
      "13          past_2th_day  0.013495\n",
      "14          past_4th_day  0.013230\n",
      "15          past_1th_day  0.012455\n",
      "16        past_5day_mean  0.012184\n",
      "17          past_6th_day  0.011176\n",
      "18        past_4day_mean  0.011176\n",
      "19          past_5th_day  0.011131\n",
      "20          past_7th_day  0.010446\n",
      "21        past_3day_mean  0.010372\n",
      "22  Past_21day_tot_promo  0.006585\n",
      "23   Past_7day_tot_promo  0.004087\n",
      "24   Past_6day_tot_promo  0.003708\n",
      "25  Past_14day_tot_promo  0.003319\n",
      "26   Past_5day_tot_promo  0.002326\n",
      "27   Past_4day_tot_promo  0.001084\n",
      "28   Past_3day_tot_promo  0.001055\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #2]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.558142\n",
      "1        past_14day_mean  0.092486\n",
      "2   past_14day_sum_decay  0.049093\n",
      "3        past_21day_mean  0.034743\n",
      "4         past_7day_mean  0.021584\n",
      "5      predict_day_promo  0.020030\n",
      "6    past_7day_sum_decay  0.016446\n",
      "7           past_5th_day  0.016109\n",
      "8    past_6day_sum_decay  0.014372\n",
      "9           past_3th_day  0.014043\n",
      "10   past_5day_sum_decay  0.013680\n",
      "11   past_3day_sum_decay  0.013232\n",
      "12   past_4day_sum_decay  0.013114\n",
      "13          past_4th_day  0.012973\n",
      "14          past_2th_day  0.012675\n",
      "15        past_6day_mean  0.012116\n",
      "16          past_1th_day  0.011919\n",
      "17        past_5day_mean  0.011190\n",
      "18          past_7th_day  0.010971\n",
      "19        past_4day_mean  0.010329\n",
      "20          past_6th_day  0.010028\n",
      "21        past_3day_mean  0.009590\n",
      "22  Past_21day_tot_promo  0.007497\n",
      "23  Past_14day_tot_promo  0.003529\n",
      "24   Past_5day_tot_promo  0.003229\n",
      "25   Past_7day_tot_promo  0.002177\n",
      "26   Past_6day_tot_promo  0.002164\n",
      "27   Past_4day_tot_promo  0.001674\n",
      "28   Past_3day_tot_promo  0.000865\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #3]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.647616\n",
      "1   past_14day_sum_decay  0.067751\n",
      "2        past_21day_mean  0.028255\n",
      "3        past_14day_mean  0.022558\n",
      "4    past_7day_sum_decay  0.017047\n",
      "5    past_6day_sum_decay  0.015212\n",
      "6         past_7day_mean  0.014314\n",
      "7           past_4th_day  0.013933\n",
      "8           past_3th_day  0.013585\n",
      "9    past_5day_sum_decay  0.012933\n",
      "10        past_5day_mean  0.012770\n",
      "11     predict_day_promo  0.012187\n",
      "12        past_6day_mean  0.012161\n",
      "13   past_4day_sum_decay  0.011685\n",
      "14          past_2th_day  0.011505\n",
      "15   past_3day_sum_decay  0.011492\n",
      "16          past_1th_day  0.011066\n",
      "17          past_5th_day  0.009961\n",
      "18        past_4day_mean  0.009597\n",
      "19          past_7th_day  0.009231\n",
      "20          past_6th_day  0.008930\n",
      "21        past_3day_mean  0.008406\n",
      "22  Past_21day_tot_promo  0.006302\n",
      "23  Past_14day_tot_promo  0.003258\n",
      "24   Past_7day_tot_promo  0.002763\n",
      "25   Past_6day_tot_promo  0.002145\n",
      "26   Past_5day_tot_promo  0.001741\n",
      "27   Past_4day_tot_promo  0.000908\n",
      "28   Past_3day_tot_promo  0.000688\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #4]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.676136\n",
      "1   past_14day_sum_decay  0.033101\n",
      "2        past_21day_mean  0.026647\n",
      "3        past_14day_mean  0.021483\n",
      "4         past_4day_mean  0.021318\n",
      "5           past_3th_day  0.018387\n",
      "6    past_7day_sum_decay  0.016183\n",
      "7    past_6day_sum_decay  0.014460\n",
      "8         past_7day_mean  0.013690\n",
      "9    past_5day_sum_decay  0.013432\n",
      "10   past_4day_sum_decay  0.012858\n",
      "11        past_5day_mean  0.012343\n",
      "12          past_4th_day  0.012087\n",
      "13     predict_day_promo  0.011775\n",
      "14        past_6day_mean  0.011278\n",
      "15   past_3day_sum_decay  0.011276\n",
      "16          past_2th_day  0.011250\n",
      "17          past_1th_day  0.009592\n",
      "18          past_7th_day  0.009208\n",
      "19          past_5th_day  0.008876\n",
      "20          past_6th_day  0.008847\n",
      "21        past_3day_mean  0.007906\n",
      "22  Past_21day_tot_promo  0.006157\n",
      "23  Past_14day_tot_promo  0.003070\n",
      "24   Past_7day_tot_promo  0.002621\n",
      "25   Past_6day_tot_promo  0.002134\n",
      "26   Past_5day_tot_promo  0.001848\n",
      "27   Past_4day_tot_promo  0.001177\n",
      "28   Past_3day_tot_promo  0.000861\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #5]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.670464\n",
      "1        past_21day_mean  0.028119\n",
      "2   past_14day_sum_decay  0.024643\n",
      "3        past_14day_mean  0.023957\n",
      "4    past_7day_sum_decay  0.016890\n",
      "5         past_7day_mean  0.015736\n",
      "6      predict_day_promo  0.015656\n",
      "7    past_6day_sum_decay  0.014753\n",
      "8           past_3th_day  0.014044\n",
      "9    past_5day_sum_decay  0.013909\n",
      "10   past_3day_sum_decay  0.013817\n",
      "11          past_2th_day  0.013572\n",
      "12        past_6day_mean  0.013300\n",
      "13   past_4day_sum_decay  0.013292\n",
      "14          past_4th_day  0.012919\n",
      "15        past_5day_mean  0.012104\n",
      "16          past_1th_day  0.011405\n",
      "17          past_7th_day  0.011111\n",
      "18          past_5th_day  0.011032\n",
      "19        past_4day_mean  0.010766\n",
      "20          past_6th_day  0.009486\n",
      "21        past_3day_mean  0.009462\n",
      "22  Past_21day_tot_promo  0.006221\n",
      "23  Past_14day_tot_promo  0.003507\n",
      "24   Past_7day_tot_promo  0.002983\n",
      "25   Past_5day_tot_promo  0.002386\n",
      "26   Past_6day_tot_promo  0.002093\n",
      "27   Past_4day_tot_promo  0.001581\n",
      "28   Past_3day_tot_promo  0.000793\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #6]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.635611\n",
      "1        past_21day_mean  0.030709\n",
      "2      predict_day_promo  0.030042\n",
      "3   past_14day_sum_decay  0.029589\n",
      "4        past_14day_mean  0.024732\n",
      "5    past_7day_sum_decay  0.017710\n",
      "6         past_7day_mean  0.016224\n",
      "7    past_6day_sum_decay  0.015307\n",
      "8           past_3th_day  0.015218\n",
      "9    past_5day_sum_decay  0.014397\n",
      "10   past_3day_sum_decay  0.014022\n",
      "11   past_4day_sum_decay  0.013685\n",
      "12        past_6day_mean  0.013611\n",
      "13          past_1th_day  0.013601\n",
      "14          past_4th_day  0.013351\n",
      "15          past_2th_day  0.013246\n",
      "16        past_5day_mean  0.012536\n",
      "17          past_7th_day  0.011199\n",
      "18        past_4day_mean  0.010959\n",
      "19          past_5th_day  0.010930\n",
      "20          past_6th_day  0.010465\n",
      "21        past_3day_mean  0.009795\n",
      "22  Past_21day_tot_promo  0.007459\n",
      "23   Past_7day_tot_promo  0.003960\n",
      "24   Past_6day_tot_promo  0.003518\n",
      "25  Past_14day_tot_promo  0.003296\n",
      "26   Past_5day_tot_promo  0.002488\n",
      "27   Past_3day_tot_promo  0.001198\n",
      "28   Past_4day_tot_promo  0.001140\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #7]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.504008\n",
      "1        past_21day_mean  0.111125\n",
      "2        past_14day_mean  0.082420\n",
      "3      predict_day_promo  0.033571\n",
      "4   past_14day_sum_decay  0.023108\n",
      "5    past_7day_sum_decay  0.016033\n",
      "6           past_7th_day  0.015436\n",
      "7         past_7day_mean  0.015092\n",
      "8           past_3th_day  0.014902\n",
      "9    past_6day_sum_decay  0.014571\n",
      "10   past_5day_sum_decay  0.013931\n",
      "11   past_3day_sum_decay  0.013755\n",
      "12   past_4day_sum_decay  0.013402\n",
      "13          past_2th_day  0.013210\n",
      "14          past_4th_day  0.012980\n",
      "15        past_6day_mean  0.012399\n",
      "16          past_1th_day  0.011946\n",
      "17        past_5day_mean  0.011900\n",
      "18          past_5th_day  0.011738\n",
      "19        past_4day_mean  0.010885\n",
      "20          past_6th_day  0.010257\n",
      "21        past_3day_mean  0.009743\n",
      "22  Past_21day_tot_promo  0.007715\n",
      "23   Past_6day_tot_promo  0.004029\n",
      "24   Past_7day_tot_promo  0.003950\n",
      "25  Past_14day_tot_promo  0.003790\n",
      "26   Past_5day_tot_promo  0.001725\n",
      "27   Past_4day_tot_promo  0.001193\n",
      "28   Past_3day_tot_promo  0.001188\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.381578\n",
      "1        past_21day_mean  0.253468\n",
      "2      predict_day_promo  0.035229\n",
      "3        past_14day_mean  0.028886\n",
      "4   past_14day_sum_decay  0.025979\n",
      "5    past_7day_sum_decay  0.018536\n",
      "6         past_7day_mean  0.017715\n",
      "7           past_3th_day  0.017439\n",
      "8    past_6day_sum_decay  0.016318\n",
      "9    past_5day_sum_decay  0.015689\n",
      "10          past_2th_day  0.015631\n",
      "11          past_4th_day  0.014909\n",
      "12   past_3day_sum_decay  0.014872\n",
      "13   past_4day_sum_decay  0.014755\n",
      "14        past_6day_mean  0.014518\n",
      "15          past_1th_day  0.014086\n",
      "16          past_6th_day  0.013975\n",
      "17        past_5day_mean  0.013586\n",
      "18          past_7th_day  0.013417\n",
      "19          past_5th_day  0.013066\n",
      "20        past_4day_mean  0.012745\n",
      "21        past_3day_mean  0.010818\n",
      "22  Past_21day_tot_promo  0.007405\n",
      "23  Past_14day_tot_promo  0.006284\n",
      "24   Past_7day_tot_promo  0.003078\n",
      "25   Past_6day_tot_promo  0.001789\n",
      "26   Past_4day_tot_promo  0.001568\n",
      "27   Past_5day_tot_promo  0.001475\n",
      "28   Past_3day_tot_promo  0.001187\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #9]\n",
      "                 feature      gain\n",
      "0        past_21day_mean  0.554451\n",
      "1   past_21day_sum_decay  0.091924\n",
      "2      predict_day_promo  0.040452\n",
      "3        past_14day_mean  0.027891\n",
      "4   past_14day_sum_decay  0.023347\n",
      "5           past_5th_day  0.017539\n",
      "6    past_7day_sum_decay  0.017012\n",
      "7         past_7day_mean  0.016623\n",
      "8           past_3th_day  0.015933\n",
      "9           past_4th_day  0.015126\n",
      "10   past_6day_sum_decay  0.014696\n",
      "11   past_3day_sum_decay  0.014419\n",
      "12          past_2th_day  0.014207\n",
      "13   past_5day_sum_decay  0.013847\n",
      "14        past_6day_mean  0.013787\n",
      "15   past_4day_sum_decay  0.013644\n",
      "16          past_7th_day  0.013563\n",
      "17          past_1th_day  0.012721\n",
      "18        past_5day_mean  0.012190\n",
      "19          past_6th_day  0.011775\n",
      "20  Past_21day_tot_promo  0.011411\n",
      "21        past_4day_mean  0.011193\n",
      "22        past_3day_mean  0.010462\n",
      "23  Past_14day_tot_promo  0.005068\n",
      "24   Past_7day_tot_promo  0.002265\n",
      "25   Past_6day_tot_promo  0.001457\n",
      "26   Past_5day_tot_promo  0.001419\n",
      "27   Past_4day_tot_promo  0.000874\n",
      "28   Past_3day_tot_promo  0.000705\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #10]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.551412\n",
      "1        past_21day_mean  0.133026\n",
      "2      predict_day_promo  0.029212\n",
      "3        past_14day_mean  0.024471\n",
      "4   past_14day_sum_decay  0.023832\n",
      "5    past_7day_sum_decay  0.016287\n",
      "6         past_7day_mean  0.015058\n",
      "7           past_4th_day  0.015007\n",
      "8    past_6day_sum_decay  0.014611\n",
      "9           past_3th_day  0.014412\n",
      "10   past_5day_sum_decay  0.014392\n",
      "11   past_4day_sum_decay  0.013083\n",
      "12        past_6day_mean  0.012940\n",
      "13        past_5day_mean  0.012927\n",
      "14   past_3day_sum_decay  0.012614\n",
      "15          past_2th_day  0.012432\n",
      "16          past_1th_day  0.011658\n",
      "17          past_5th_day  0.011374\n",
      "18          past_7th_day  0.011039\n",
      "19        past_4day_mean  0.010687\n",
      "20          past_6th_day  0.009994\n",
      "21        past_3day_mean  0.008847\n",
      "22  Past_21day_tot_promo  0.006650\n",
      "23  Past_14day_tot_promo  0.004300\n",
      "24   Past_7day_tot_promo  0.004238\n",
      "25   Past_6day_tot_promo  0.001908\n",
      "26   Past_4day_tot_promo  0.001556\n",
      "27   Past_5day_tot_promo  0.001195\n",
      "28   Past_3day_tot_promo  0.000838\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #11]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.636301\n",
      "1        past_21day_mean  0.047695\n",
      "2      predict_day_promo  0.029223\n",
      "3   past_14day_sum_decay  0.025016\n",
      "4        past_14day_mean  0.024093\n",
      "5           past_3th_day  0.020539\n",
      "6    past_7day_sum_decay  0.015998\n",
      "7         past_7day_mean  0.015503\n",
      "8    past_6day_sum_decay  0.014044\n",
      "9           past_4th_day  0.013666\n",
      "10   past_5day_sum_decay  0.013522\n",
      "11   past_4day_sum_decay  0.013022\n",
      "12          past_2th_day  0.012339\n",
      "13        past_6day_mean  0.012278\n",
      "14   past_3day_sum_decay  0.011959\n",
      "15        past_5day_mean  0.011720\n",
      "16          past_7th_day  0.011526\n",
      "17          past_5th_day  0.011086\n",
      "18        past_4day_mean  0.011052\n",
      "19          past_1th_day  0.010450\n",
      "20          past_6th_day  0.009853\n",
      "21        past_3day_mean  0.008709\n",
      "22  Past_21day_tot_promo  0.005822\n",
      "23  Past_14day_tot_promo  0.005144\n",
      "24   Past_7day_tot_promo  0.003456\n",
      "25   Past_6day_tot_promo  0.002557\n",
      "26   Past_4day_tot_promo  0.001391\n",
      "27   Past_5day_tot_promo  0.001158\n",
      "28   Past_3day_tot_promo  0.000879\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #12]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.614674\n",
      "1        past_21day_mean  0.047388\n",
      "2      predict_day_promo  0.032206\n",
      "3   past_14day_sum_decay  0.026014\n",
      "4        past_14day_mean  0.025578\n",
      "5    past_7day_sum_decay  0.018154\n",
      "6         past_7day_mean  0.016408\n",
      "7    past_6day_sum_decay  0.015556\n",
      "8           past_3th_day  0.015228\n",
      "9    past_5day_sum_decay  0.014831\n",
      "10   past_4day_sum_decay  0.014576\n",
      "11        past_6day_mean  0.014293\n",
      "12          past_2th_day  0.014022\n",
      "13          past_4th_day  0.014009\n",
      "14   past_3day_sum_decay  0.013903\n",
      "15        past_5day_mean  0.012812\n",
      "16          past_1th_day  0.012179\n",
      "17        past_4day_mean  0.011849\n",
      "18          past_7th_day  0.011619\n",
      "19          past_5th_day  0.011619\n",
      "20        past_3day_mean  0.010836\n",
      "21          past_6th_day  0.010626\n",
      "22  Past_21day_tot_promo  0.006268\n",
      "23  Past_14day_tot_promo  0.005159\n",
      "24   Past_7day_tot_promo  0.004032\n",
      "25   Past_6day_tot_promo  0.002199\n",
      "26   Past_5day_tot_promo  0.001902\n",
      "27   Past_4day_tot_promo  0.001265\n",
      "28   Past_3day_tot_promo  0.000796\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #13]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.587685\n",
      "1        past_21day_mean  0.053911\n",
      "2      predict_day_promo  0.044274\n",
      "3   past_14day_sum_decay  0.026193\n",
      "4        past_14day_mean  0.026052\n",
      "5    past_7day_sum_decay  0.018465\n",
      "6         past_7day_mean  0.017032\n",
      "7           past_3th_day  0.015826\n",
      "8    past_6day_sum_decay  0.015627\n",
      "9    past_5day_sum_decay  0.015134\n",
      "10   past_3day_sum_decay  0.015050\n",
      "11          past_1th_day  0.015045\n",
      "12        past_6day_mean  0.014734\n",
      "13   past_4day_sum_decay  0.014356\n",
      "14          past_4th_day  0.014311\n",
      "15          past_2th_day  0.013620\n",
      "16        past_5day_mean  0.013114\n",
      "17          past_7th_day  0.011988\n",
      "18          past_5th_day  0.011941\n",
      "19        past_4day_mean  0.011834\n",
      "20          past_6th_day  0.011428\n",
      "21        past_3day_mean  0.010710\n",
      "22  Past_21day_tot_promo  0.006452\n",
      "23  Past_14day_tot_promo  0.005087\n",
      "24   Past_7day_tot_promo  0.003148\n",
      "25   Past_6day_tot_promo  0.002161\n",
      "26   Past_5day_tot_promo  0.001962\n",
      "27   Past_4day_tot_promo  0.001471\n",
      "28   Past_3day_tot_promo  0.001389\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #14]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.381186\n",
      "1        past_21day_mean  0.261157\n",
      "2      predict_day_promo  0.049007\n",
      "3        past_14day_mean  0.026672\n",
      "4   past_14day_sum_decay  0.023577\n",
      "5    past_7day_sum_decay  0.017029\n",
      "6           past_7th_day  0.015952\n",
      "7         past_7day_mean  0.015833\n",
      "8           past_3th_day  0.015526\n",
      "9    past_6day_sum_decay  0.014534\n",
      "10   past_3day_sum_decay  0.014348\n",
      "11   past_5day_sum_decay  0.014276\n",
      "12   past_4day_sum_decay  0.014182\n",
      "13          past_4th_day  0.013894\n",
      "14          past_2th_day  0.013877\n",
      "15        past_6day_mean  0.013695\n",
      "16          past_1th_day  0.013055\n",
      "17          past_5th_day  0.012580\n",
      "18        past_5day_mean  0.012479\n",
      "19        past_4day_mean  0.011999\n",
      "20          past_6th_day  0.011442\n",
      "21        past_3day_mean  0.010050\n",
      "22  Past_21day_tot_promo  0.007290\n",
      "23  Past_14day_tot_promo  0.005849\n",
      "24   Past_7day_tot_promo  0.005229\n",
      "25   Past_6day_tot_promo  0.001848\n",
      "26   Past_4day_tot_promo  0.001464\n",
      "27   Past_5day_tot_promo  0.001303\n",
      "28   Past_3day_tot_promo  0.000668\n",
      "\n",
      "==================================================\n",
      "Feature Importance Report [Random Forest Model #15]\n",
      "                 feature      gain\n",
      "0   past_21day_sum_decay  0.518395\n",
      "1        past_21day_mean  0.117640\n",
      "2      predict_day_promo  0.036878\n",
      "3        past_14day_mean  0.028674\n",
      "4   past_14day_sum_decay  0.026176\n",
      "5    past_7day_sum_decay  0.018688\n",
      "6         past_7day_mean  0.018024\n",
      "7           past_3th_day  0.016655\n",
      "8    past_6day_sum_decay  0.015603\n",
      "9    past_5day_sum_decay  0.015595\n",
      "10          past_4th_day  0.015111\n",
      "11   past_4day_sum_decay  0.015042\n",
      "12        past_6day_mean  0.015027\n",
      "13          past_2th_day  0.014593\n",
      "14   past_3day_sum_decay  0.014389\n",
      "15        past_5day_mean  0.013889\n",
      "16          past_6th_day  0.013847\n",
      "17          past_1th_day  0.013564\n",
      "18          past_5th_day  0.013389\n",
      "19          past_7th_day  0.013015\n",
      "20        past_4day_mean  0.012658\n",
      "21        past_3day_mean  0.010715\n",
      "22  Past_21day_tot_promo  0.007682\n",
      "23  Past_14day_tot_promo  0.005929\n",
      "24   Past_7day_tot_promo  0.003679\n",
      "25   Past_6day_tot_promo  0.001482\n",
      "26   Past_5day_tot_promo  0.001386\n",
      "27   Past_4day_tot_promo  0.001359\n",
      "28   Past_3day_tot_promo  0.000917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_pred_days):\n",
    "    print(\"=\" * 50)\n",
    "    print ('Feature Importance Report [Random Forest Model #{}]'.format(i))\n",
    "    \n",
    "    feature_train_add = feature_train.copy()\n",
    "    feature_train_add['predict_day_promo']= future_promo_train.iloc[:,i]\n",
    "    \n",
    "    feature_importance = pd.DataFrame(\n",
    "        sorted(zip(feature_train_add.columns, model_RF_all[i].feature_importances_ ),\n",
    "        key=lambda x: x[1], reverse=True), columns = ['feature','gain']\n",
    "    )\n",
    "    \n",
    "    print(feature_importance.to_string())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(models, feature, future_promo, start_date):\n",
    "    target_predic_all = {}\n",
    "    future_date_range = pd.date_range(start_date, periods=16) \n",
    "    \n",
    "    length = len(models) \n",
    "    for i in range (length):   \n",
    "        feature_add = pd.concat([feature,future_promo.iloc[:,i]], axis=1)\n",
    "        target_predic = models[i].predict(feature_add)\n",
    " \n",
    "        if len(target_predic.shape) == 2:\n",
    "            target_predic = target_predic[:,0]\n",
    "        \n",
    "        target_predic_all[future_date_range[i]] = target_predic\n",
    "        target_predic_all = pd.DataFrame(target_predic_all)\n",
    "    \n",
    "    return target_predic_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_val_all_RF = predict_all(model_RF_all, feature_val, future_promo_val, val_date)\n",
    "predict_test_all_RF = predict_all(model_RF_all, feature_test, future_promo_test, test_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model Performance Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nwrmsle_cal(predict, actual, weight):\n",
    "    #predict = predict.values\n",
    "    #actual = actual.values\n",
    "    \n",
    "    error = (actual - np.array(predict)) ** 2\n",
    "    error = error.sum(axis=1) * weight\n",
    "    nwrmsle = np.sqrt(error.sum() / weight.sum() / 16)\n",
    "                  \n",
    "    return nwrmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_cal(train, predict, target, dates):\n",
    "    y = np.array(predict)\n",
    "    forcast = pd.DataFrame(\n",
    "    y, index=train.index,\n",
    "    columns=pd.date_range(dates, periods=16)).stack().to_frame(\"predict_unit_sales\")\n",
    "    \n",
    "    forcast.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "    \n",
    "    forcast[\"predict_unit_sales\"] = np.expm1(forcast[\"predict_unit_sales\"])\n",
    "    \n",
    "    actual = target.stack().to_frame(\"actual_unit_sales\")\n",
    "    actual.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "    actual[\"actual_unit_sales\"] = np.expm1(actual[\"actual_unit_sales\"])\n",
    "    \n",
    "    concat_data = pd.concat([actual,forcast], axis=1)\n",
    "    concat_data = concat_data[(concat_data['actual_unit_sales'] !=0 )|(concat_data['predict_unit_sales'] != 0)]\n",
    "    \n",
    "    \n",
    "    a = concat_data['actual_unit_sales'].values\n",
    "    f = concat_data['predict_unit_sales'].values\n",
    "    smape = np.mean(abs(a - f) / (abs(a) + abs(f)) / 2) * 100\n",
    "    \n",
    "    return smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwrmsle_val_RF = nwrmsle_cal(predict_val_all_RF, target_val, weight_matrix )\n",
    "rmse_val_RF = math.sqrt(mean_squared_error(predict_val_all_RF.values, target_val.values))\n",
    "smape_val_RF = smape_cal(df_train_sales, predict_val_all_RF, target_val, val_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWRMSLE on Validation Data Set [Random Forest Regression]: 0.657\n",
      "RMSLE on Validation Data Set [Random Forest Regression]: 0.657\n",
      "sMAPE on Validation Data Set [Random Forest Regression]: 28.3%\n"
     ]
    }
   ],
   "source": [
    "print('NWRMSLE on Validation Data Set [Random Forest Regression]: {:.3f}'.format(nwrmsle_val_RF))\n",
    "print('RMSLE on Validation Data Set [Random Forest Regression]: {:.3f}'.format(rmse_val_RF))\n",
    "print('sMAPE on Validation Data Set [Random Forest Regression]: {:.1f}%'.format(smape_val_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2. Deep Learning Model (DL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creation(input_dim_, dropout_rate=0.0):\n",
    "    # Set Initial Weights \n",
    "    kernel_initializer_ = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=1)\n",
    "    \n",
    "    # Define Netwrok Type\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Hidden layer\n",
    "    model.add(Dense(32, activation='relu', input_shape=(input_dim_,),kernel_initializer=kernel_initializer_))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(16, activation='relu', kernel_initializer=kernel_initializer_))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(8, activation='relu', kernel_initializer=kernel_initializer_))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='relu', kernel_initializer=kernel_initializer_))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer=\"adam\")\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_dl(feature_train, target_train, feature_val, target_val, epochs_):\n",
    "    input_dim = feature_train.shape[1]\n",
    "           \n",
    "    # Define Call Back for Early Stop\n",
    "    call_back = [\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=50, verbose=0, mode='auto')\n",
    "    ]\n",
    "       \n",
    "    # Initialize Model\n",
    "    model = model_creation(input_dim)\n",
    "    \n",
    "    # Train DLModel\n",
    "    model_info = model.fit(feature_train, \n",
    "                           target_train,\n",
    "                           batch_size=feature_train.shape[0],\n",
    "                           epochs=epochs_,\n",
    "                           verbose=0,\n",
    "                           callbacks = call_back,\n",
    "                           validation_data=(feature_val, target_val)\n",
    "                          )\n",
    "    return model, model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training Deep Learning Model #0 ...\n",
      "\n",
      "==================================================\n",
      "Training Deep Learning Model #1 ...\n",
      "\n",
      "==================================================\n",
      "Training Deep Learning Model #2 ...\n",
      "\n",
      "==================================================\n",
      "Training Deep Learning Model #3 ...\n",
      "\n",
      "==================================================\n",
      "Training Deep Learning Model #4 ...\n",
      "\n",
      "==================================================\n",
      "Training Deep Learning Model #5 ...\n",
      "\n",
      "==================================================\n",
      "Training Deep Learning Model #6 ...\n",
      "\n",
      "==================================================\n",
      "Training Deep Learning Model #7 ...\n"
     ]
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    epochs_ = 2\n",
    "else:\n",
    "    epochs_ = 1000\n",
    "    \n",
    "model_dl_all = [] # Model list for storing all 16 models\n",
    "model_info_dl_all= [] # List of storing model training information, such as val_loos, val_acc. \n",
    "\n",
    "feature_train_add = pd.DataFrame()\n",
    "feature_val_add = pd.DataFrame()\n",
    "feature_test_add = pd.DataFrame()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# future_promo contains 16 days data, get the one on prediction date and use as a feature\n",
    "\n",
    "for i in range(n_pred_days): \n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print('Training Deep Learning Model #{} ...'.format(i))\n",
    "    \n",
    "    feature_train_add = pd.concat([feature_train,future_promo_train.iloc[:,i]], axis=1)\n",
    "    feature_val_add = pd.concat([feature_val,future_promo_val.iloc[:,i]], axis=1)\n",
    "    feature_test_add = pd.concat([feature_test,future_promo_test.iloc[:,i]], axis=1)\n",
    "    \n",
    "\n",
    "    model_dl, model_info_dl = model_training_dl(feature_train_add,\n",
    "                                                target_train.iloc[:,i], \n",
    "                                                feature_val_add,\n",
    "                                                target_val.iloc[:,i],\n",
    "                                                epochs_)  \n",
    "    model_dl_all.append(model_dl)\n",
    "    model_info_dl_all.append(model_info_dl)\n",
    "    print(\"\")\n",
    "    \n",
    "end = time.time()\n",
    "print (\"Time of Training {} Deep Learning Models: {:.2f} Mins\".format(n_pred_days, (end - start) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_val_all_DL = predict_all(model_dl_all, feature_val, future_promo_val, val_date)\n",
    "predict_test_all_DL = predict_all(model_dl_all, feature_test, future_promo_test, test_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwrmsle_val_DL = nwrmsle_cal(predict_val_all_DL, target_val, weight_matrix )\n",
    "rmse_val_DL = math.sqrt(mean_squared_error(predict_val_all_DL.values, target_val.values))\n",
    "smape_val_DL = smape_cal(df_train_sales, predict_val_all_DL, target_val, val_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NWRMSLE on Validation Data Set [DL]: {:.3f}'.format(nwrmsle_val_DL))\n",
    "print('RMSLE on Validation Data Set [DL]: {:.3f}'.format(rmse_val_DL))\n",
    "print('sMAPE on Validation Data Set [DL]: {:.1f}%'.format(smape_val_DL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3. LGBM Model\n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LGBM_all = [] # Model list for storing all 16 models\n",
    "\n",
    "feature_train_add = pd.DataFrame()\n",
    "feature_val_add = pd.DataFrame()\n",
    "feature_test_add = pd.DataFrame()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# future_promo contains 16 days data, get the one on prediction date and use as a feature\n",
    "\n",
    "for i in range(n_pred_days): \n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print('Training LGBM Model {} ...'.format(i))\n",
    "\n",
    "    feature_train_add = pd.concat([feature_train,future_promo_train.iloc[:,i]], axis=1)\n",
    "    feature_val_add = pd.concat([feature_val,future_promo_val.iloc[:,i]], axis=1)\n",
    "    feature_test_add = pd.concat([feature_test,future_promo_test.iloc[:,i]], axis=1)\n",
    "\n",
    "    \n",
    "    d_train = lgb.Dataset(\n",
    "        feature_train_add, label = target_train.iloc[:,i],\n",
    "        weight =  weight_matrix\n",
    "    )\n",
    "    \n",
    "    \n",
    "    d_val = lgb.Dataset(\n",
    "        feature_val_add, label = target_val.iloc[:,i],\n",
    "        reference = d_train,\n",
    "        weight =  weight_matrix\n",
    "    )\n",
    "    \n",
    "    # Set Up GBM Hyperparameter\n",
    "    params = {}\n",
    "    params['learning_rate'] = 0.05\n",
    "    params['boosting_type'] = 'gbdt'\n",
    "    params['objective'] = 'regression_l2'\n",
    "    params['metric'] = 'l2'\n",
    "    params['num_leaves'] = 80\n",
    "    params['max_depth'] = 8\n",
    "    params['min_data_in_leaf'] = 200\n",
    "    params['feature_fraction'] = 0.75\n",
    "    params[ 'bagging_fraction'] = 0.75\n",
    "    params[ 'bagging_freq'] = 1\n",
    "    params[ 'num_threads'] = 4\n",
    "\n",
    "    n_round = 1000\n",
    "\n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        d_train, \n",
    "        num_boost_round=n_round,\n",
    "        valid_sets=[d_train, d_val], \n",
    "        early_stopping_rounds=100, \n",
    "        verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    model_LGBM_all.append(model)\n",
    "    print(\"\")\n",
    "    \n",
    "end = time.time()\n",
    "print (\"Time of Training {} LGBM Models: {:.2f} Mins\".format(n_pred_days, (end - start) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(model_LGBM_all)):\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print ('Feature Importance Report [LGBM #{}]'.format(i))\n",
    "    \n",
    "    feature_train_add = feature_train.copy()\n",
    "    feature_train_add['predict_day_promo'] = future_promo_train.iloc[:,i]\n",
    "    \n",
    "    feature_importance = pd.DataFrame(\n",
    "        sorted(zip(feature_train_add.columns, model_LGBM_all[i].feature_importance(\"gain\")),\n",
    "               key=lambda x: x[1], reverse=True), columns = ['feature', 'gain']\n",
    "    )\n",
    "    \n",
    "    print(feature_importance.to_string())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_LGBM (models, feature,future_promo, start_date):\n",
    "    target_predic_all = {}\n",
    "    future_date_range = pd.date_range(start_date, periods=16)\n",
    "    \n",
    "    length = len(models) \n",
    "    for i in range (0, length):   \n",
    "        feature_add = pd.concat([feature,future_promo.iloc[:,i]], axis=1)\n",
    "        target_predic = models[i].predict(feature_add,num_iteration=models[i].best_iteration)\n",
    "        target_predic_all[future_date_range[i]] = target_predic\n",
    "        target_predic_all = pd.DataFrame(target_predic_all)\n",
    "    \n",
    "    return target_predic_all\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_val_all_LGBM = predict_all_LGBM (model_LGBM_all, feature_val, future_promo_val, val_date)\n",
    "predict_test_all_LGBM = predict_all_LGBM (model_LGBM_all, feature_test, future_promo_test, test_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwrmsle_val_LGBM = nwrmsle_cal(predict_val_all_LGBM, target_val, weight_matrix )\n",
    "rmse_val_LGBM =math.sqrt(mean_squared_error(predict_val_all_LGBM.values, target_val.values))\n",
    "smape_val_LGBM = smape_cal(df_train_sales, predict_val_all_LGBM, target_val, val_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NWRMSLE on Validation Data Set [LGBM]: {:.3f}'.format(nwrmsle_val_LGBM))\n",
    "print('RMSLE on Validation Data Set [LGBM]: {:.3f}'.format(rmse_val_LGBM))\n",
    "print('sMAPE on Validation Data Set [LGBM]: {:.1f}%'.format(smape_val_LGBM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Submission\n",
    "#### Change Back from Logrithmic Scale to Linear Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(predict_test_all_LGBM)\n",
    "\n",
    "df_predict = pd.DataFrame(\n",
    "    y_test, \n",
    "    index=df_train_sales.index,\n",
    "    columns=pd.date_range(test_date, periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "\n",
    "df_predict.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "df_test.set_index([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "df_sub = df_test[['id']].join(df_predict, how=\"left\").fillna(0)\n",
    "df_sub[\"unit_sales\"] = np.expm1(df_sub[\"unit_sales\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Prediction Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('Submission.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
